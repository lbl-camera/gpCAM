{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f38aa3",
   "metadata": {},
   "source": [
    "# gpCAM Advanced Application\n",
    "In this notebook, we will go through many features of gpCAM. Work through it \n",
    "and you are ready for your own autonomous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "####install gpcam here if you do not have already done so\n",
    "#!pip install gpcam==8.1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dc1e7",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d11477",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "def plot(x,y,z,data = None):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(x = x, y = y,z=z))\n",
    "    if data is not None: \n",
    "        fig.add_trace(go.Scatter3d(x=data[:,0], y=data[:,1], z=data[:,2],\n",
    "                                   mode='markers'))\n",
    "\n",
    "    fig.update_layout(title='Posterior Mean', autosize=True,\n",
    "                  width=800, height=800,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b7ecb",
   "metadata": {},
   "source": [
    "## Defining Prediction Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9983e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((10000,2))\n",
    "x = np.linspace(0,10,100)\n",
    "y = np.linspace(0,10,100)\n",
    "x,y = np.meshgrid(x,y)\n",
    "counter = 0\n",
    "for i in  range(100):\n",
    "    for j in range(100):\n",
    "        x_pred[counter] = np.array([x[i,j],y[i,j]])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36f699",
   "metadata": {},
   "source": [
    "## Definition of Optional Customization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c19974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optional_acq_func(x,obj):\n",
    "    #this acquisition function makes the autonomous experiment a Bayesian optimization\n",
    "    #but is just here as an example. 'acq_funciton=\"ucb\"' will give you the same result\n",
    "    a = 3.0 #3.0 for 95 percent confidence interval\n",
    "    mean = obj.posterior_mean(x)[\"f(x)\"]\n",
    "    cov = obj.posterior_covariance(x)[\"v(x)\"]\n",
    "    return mean + a * np.sqrt(cov)\n",
    "\n",
    "def optional_mean_func(x,hyperparameters):\n",
    "    #the prior mean function should return a vector: a mean function evaluation for every x\n",
    "    return np.zeros((len(x)))\n",
    "\n",
    "def optional_cost_function(origin,x,arguments = None):\n",
    "    #cost pf l1 motion in the input space\n",
    "    offset = arguments[\"offset\"]\n",
    "    slope = arguments[\"slope\"]\n",
    "    d = np.abs(np.subtract(origin,x))\n",
    "    c = (d * slope) + offset\n",
    "    n = np.sum(c)\n",
    "    return n\n",
    "\n",
    "def optional_cost_update_function(costs, parameters):\n",
    "    ###defining a cost update function might look tricky but just needs a bit\n",
    "    ###of tenacity. And remember, this is optional, if you have a great guess for your costs you\n",
    "    ###don't need to update the costs. Also, if you don't account for costs, this function is not needed.\n",
    "    #In this example we just return the old parameters, but print the costs. \n",
    "    #I hope it is clear how the parameters can be fitted to the recorded costs.\n",
    "    print(\"recorded costs (from,to,costs): \", costs)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670c633-0927-4a48-b823-a59a000bb011",
   "metadata": {},
   "source": [
    "## AutonomousExperimenter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gpcam import AutonomousExperimenterGP\n",
    "\n",
    "def instrument(data):\n",
    "    print(\"Suggested by gpCAM: \")\n",
    "    for entry in data:\n",
    "        print(\"suggested:\", entry[\"x_data\"])\n",
    "        entry[\"y_data\"] = np.sin(np.linalg.norm(entry[\"x_data\"]))\n",
    "        entry[\"noise variance\"] = 0.1\n",
    "        entry[\"cost\"]  = [np.array([0,0]),entry[\"x_data\"],np.sum(entry[\"x_data\"])]\n",
    "        print(\"received: \", entry[\"y_data\"])\n",
    "    print(\"\")\n",
    "    return data\n",
    "\n",
    "#initialization\n",
    "#feel free to try different acquisition functions, e.g. optional_acq_func, \"covariance\",\n",
    "#note how costs are defined for the autonomous experimenter\n",
    "my_ae = AutonomousExperimenterGP(np.array([[0,10],[0,10]]),\n",
    "                                 np.ones((3)), np.array([[0.001,100.],[0.001,100.],[0.001,100.]]),\n",
    "                                 init_dataset_size= 20, instrument_function = instrument,\n",
    "                                 acquisition_function = optional_acq_func, \n",
    "                                 cost_function = optional_cost_function, \n",
    "                                 cost_update_function = optional_cost_update_function,\n",
    "                                 cost_function_parameters={\"offset\": 5.0, \"slope\":10.0},\n",
    "                                 kernel_function = None, calc_inv = False,\n",
    "                                 prior_mean_function = optional_mean_func,\n",
    "                                 communicate_full_dataset = False, ram_economy = True)#, info = False, prior_mean_func = optional_mean_func)\n",
    "\n",
    "\n",
    "print(\"length of the dataset: \",len(my_ae.x_data))\n",
    "\n",
    "\n",
    "#my_ae.train_async()                 #train asynchronously\n",
    "my_ae.train(method = \"global\")       #or not, or both, choose between \"global\",\"local\" and \"hgdl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ba9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update hyperparameters in case they are optimized asynchronously\n",
    "my_ae.update_hps()\n",
    "print(my_ae.gp_optimizer.hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and client can be killed if desired and in case they are optimized asynchronously\n",
    "my_ae.kill_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74908b8",
   "metadata": {},
   "source": [
    "## Initial Model Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = my_ae.gp_optimizer.posterior_mean(x_pred)[\"f(x)\"]\n",
    "f_re = f.reshape(100,100)\n",
    "\n",
    "plot(x,y,f_re, data = np.column_stack([my_ae.x_data,my_ae.y_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cfd3b",
   "metadata": {},
   "source": [
    "## The go() Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe64039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run the autonomous loop\n",
    "my_ae.go(N = 100, \n",
    "            retrain_async_at=[30,40,50,60,70,80,90],\n",
    "            retrain_globally_at = [20,22,24,26,28,30,40,50,60,70],\n",
    "            retrain_locally_at = [21,22,56],\n",
    "            acq_func_opt_setting = lambda obj: \"global\" if len(obj.data.dataset) % 2 == 0 else \"local\",\n",
    "            update_cost_func_at = (50,),\n",
    "            training_opt_max_iter = 20,\n",
    "            training_opt_pop_size = 10,\n",
    "            training_opt_tol      = 1e-6,\n",
    "            acq_func_opt_max_iter = 20,\n",
    "            acq_func_opt_pop_size = 20,\n",
    "            acq_func_opt_tol      = 1e-6,\n",
    "            number_of_suggested_measurements = 1,\n",
    "            acq_func_opt_tol_adjust = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f4474",
   "metadata": {},
   "source": [
    "## Visualization of the Resulting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa58fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(my_ae.gp_optimizer.x_data)\n",
    "\n",
    "\n",
    "\n",
    "res = my_ae.gp_optimizer.posterior_mean(x_pred)\n",
    "f = res[\"f(x)\"]\n",
    "f = f.reshape(100,100)\n",
    "\n",
    "plot(x,y,f, data = np.column_stack([my_ae.gp_optimizer.gp.x_data,my_ae.gp_optimizer.gp.y_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107abbc",
   "metadata": {},
   "source": [
    "# Running a Multi-Task GP Autonomous Data Acquisition\n",
    "This example uses 21 (!) dim robot data and 7 tasks, which you can all use or pick a subset of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9dbb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##prepare some data\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "data = np.load(\"./data/sarcos.npy\")\n",
    "print(data.shape)\n",
    "x = data[:,0:21]\n",
    "y = data[:,21:23]\n",
    "\n",
    "from gpcam import AutonomousExperimenterFvGP\n",
    "\n",
    "def instrument(data):\n",
    "    for entry in data:\n",
    "        print(\"Suggested by gpCAM: \", entry[\"x_data\"])\n",
    "        y_data = griddata(x,y,entry[\"x_data\"],method = \"nearest\", fill_value = 0)[0]\n",
    "        entry[\"noise variances\"] = np.array([0.01, 0.01])\n",
    "        entry[\"y_data\"] = y_data\n",
    "        print(\"received: \", entry[\"y_data\"])\n",
    "    print(\"\")\n",
    "    return data\n",
    "\n",
    "def acq_func(x,obj):\n",
    "    #multi-tast autonomous experiments should use a user-defined acquisition function to\n",
    "    #take full advantage of the surrogate and the uncertainty in all tasks.\n",
    "    a = 3.0 #3.0 for ~95 percent confidence interval\n",
    "    mean = obj.posterior_mean(x, x_out = np.array([0,1]))[\"f(x)\"]\n",
    "    cov = obj.posterior_covariance(x, x_out = np.array([0,1]))[\"v(x)\"]\n",
    "    return np.linalg.norm(mean, axis = 1) + a * np.linalg.norm(cov,axis = 1)\n",
    "\n",
    "\n",
    "input_space = np.array([np.array([np.min(x[:,i]),np.max(x[:,i])]) for i in range(len(x[0]))])\n",
    "print(\"index set (input space) bounds:\")\n",
    "print(input_space)\n",
    "print(\"hps bounds:\")\n",
    "hps_bounds = np.empty((23,2))\n",
    "hps_bounds[:,0] = 0.0001\n",
    "hps_bounds[:,1] = 100.0\n",
    "hps_bounds[0] = np.array([0.0001, 10000])\n",
    "print(hps_bounds)\n",
    "print(\"shape of y: \")\n",
    "print(y.shape)\n",
    "\n",
    "my_fvae = AutonomousExperimenterFvGP(input_space,init_dataset_size= 10, instrument_function = instrument,\n",
    "                                     acquisition_function=acq_func)\n",
    "\n",
    "my_fvae.train()\n",
    "my_fvae.go(N = 50, retrain_async_at=(22,), retrain_globally_at=(50,90,120), retrain_locally_at=(25,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ec757",
   "metadata": {},
   "source": [
    "## Plotting the 0th task in a 2d slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((10000,21))\n",
    "x = np.linspace(input_space[0,0],input_space[0,1],100)\n",
    "y = np.linspace(input_space[1,0],input_space[1,1],100)\n",
    "x,y = np.meshgrid(x,y)\n",
    "counter = 0\n",
    "for i in  range(100):\n",
    "    for j in range(100):\n",
    "        x_pred[counter] = np.zeros((21))\n",
    "        x_pred[counter,[0,1]] = np.array([x[i,j],y[i,j]])\n",
    "        counter += 1\n",
    "res = my_fvae.gp_optimizer.posterior_mean(x_pred, x_out = np.array([0.]))\n",
    "f = res[\"f(x)\"]\n",
    "f = f.reshape(100,100)\n",
    "\n",
    "\n",
    "plot(x,y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75e385-57d7-48ac-96cf-ec7ff99bba59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6406a-a700-4990-a233-14c80380570b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
